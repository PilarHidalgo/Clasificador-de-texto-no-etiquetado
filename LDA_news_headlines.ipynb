{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#dependencias\n",
    "#!pip install gensim\n",
    "#!pip install nltk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "\n",
    "#data = pd.read_csv('C:/Users/pv.hidalgol/Documents/noticias/ElComercio_abusosex.csv', error_bad_lines=False);\n",
    "#data = pd.read_csv('C:/Users/pv.hidalgol/Documents/noticias/ElComercio_feminicidio.csv')#, error_bad_lines=False);\n",
    "#data = pd.read_csv('C:/Users/pv.hidalgol/Documents/noticias/Peru21_feminicidio1.csv')#, error_bad_lines=False);\n",
    "#data = pd.read_csv('C:/Users/pv.hidalgol/Documents/noticias/Peru21_feminicidio.csv')#, error_bad_lines=False);\n",
    "#data = pd.read_excel('C:/Users/pv.hidalgol/Downloads/para_pili.xlsx', encoding='latin-1', delimiter='/t')#, error_bad_lines=False);\n",
    "#data_text = data[['news']]\n",
    "#data_text['index'] = data_text.index\n",
    "#documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/home/pilar/Documentos/pili/Noticias/ElComercio_feminicidio.csv',delimiter=',',encoding='utf8')#\n",
    "#data = pd.read_csv('/home/pilar/Documentos/pili/Noticias/ElComercio_abusosex.csv',delimiter=',',encoding='utf8')#"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Unnamed: 0</th>\n",
       "      <th>news</th>\n",
       "      <th>label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>hace años caminaba amiga querida miraflores ...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>uno esperado maritza garcía dignidad renunci...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>2</td>\n",
       "      <td>cuando piensan mujercitas novela escrita loui...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>3</td>\n",
       "      <td>el fallecimiento eyvi ágreda calado fondo dis...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>4</td>\n",
       "      <td>mario maría acha presentan amplia instalación...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   Unnamed: 0                                               news  label\n",
       "0           0    hace años caminaba amiga querida miraflores ...      2\n",
       "1           1    uno esperado maritza garcía dignidad renunci...      2\n",
       "2           2   cuando piensan mujercitas novela escrita loui...      2\n",
       "3           3   el fallecimiento eyvi ágreda calado fondo dis...      2\n",
       "4           4   mario maría acha presentan amplia instalación...      2"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:2: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:4: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  after removing the cwd from sys.path.\n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:5: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \"\"\"\n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:6: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:7: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  import sys\n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:8: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  \n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:9: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  if __name__ == '__main__':\n",
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:10: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  # Remove the CWD from sys.path while we load stuff.\n"
     ]
    }
   ],
   "source": [
    "for i in range(len(data)):\n",
    "    data['news'][i]=data['news'][i].replace('eyvi',\" \")\n",
    "    #data['news'][i]=data['news'][i].replace('ágreda',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('arlett',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('contreras',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('edita',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('guerrrero',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('pozo',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('adriano',\" \")\n",
    "    data['news'][i]=data['news'][i].replace('juanita',\" \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/pilar/anaconda2/envs/py3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "#data_text = data[['Texto']]\n",
    "data_text = data[['news']]\n",
    "data_text['index'] = data_text.index\n",
    "documents = data_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "longitud=len(documents)-1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>news</th>\n",
       "      <th>index</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>hace años caminaba amiga querida miraflores ...</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>uno esperado maritza garcía dignidad renunci...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>cuando piensan mujercitas novela escrita loui...</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>el fallecimiento   ágreda calado fondo distin...</td>\n",
       "      <td>3</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>mario maría acha presentan amplia instalación...</td>\n",
       "      <td>4</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                news  index\n",
       "0    hace años caminaba amiga querida miraflores ...      0\n",
       "1    uno esperado maritza garcía dignidad renunci...      1\n",
       "2   cuando piensan mujercitas novela escrita loui...      2\n",
       "3   el fallecimiento   ágreda calado fondo distin...      3\n",
       "4   mario maría acha presentan amplia instalación...      4"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "documents[:5]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to /home/pilar/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n",
      "[nltk_data] Downloading package wordnet to /home/pilar/nltk_data...\n",
      "[nltk_data]   Package wordnet is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import nltk\n",
    "import gensim\n",
    "from gensim.utils import simple_preprocess\n",
    "from gensim.parsing.preprocessing import STOPWORDS\n",
    "from nltk.stem import WordNetLemmatizer, SnowballStemmer\n",
    "from nltk.stem.porter import *\n",
    "import numpy as np\n",
    "np.random.seed(2018)\n",
    "nltk.download('stopwords')\n",
    "nltk.download('wordnet')\n",
    "from nltk.corpus import stopwords\n",
    "from sklearn.manifold import TSNE\n",
    "\n",
    "# a t-SNE model\n",
    "# angle value close to 1 means sacrificing accuracy for speed\n",
    "# pca initializtion usually leads to better results \n",
    "tsne_model = TSNE(n_components=2, verbose=1, random_state=0, angle=.99, init='pca')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Lemmatize example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words(\"spanish\")) \n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Preproceso"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(text):\n",
    "    result = []\n",
    "    for token in gensim.utils.simple_preprocess(text):\n",
    "        if token not in stop_words and len(token) > 3:\n",
    "            #text = re.sub(r'[^\\w\\s\\n]','',text, re.UNICODE)\n",
    "            #text = text.lower()#.split()\n",
    "            #text = [lemmatizer.lemmatize(token) for token in text.split(\",\")]\n",
    "            #text = [lemmatizer.lemmatize(token, \"v\") for token in text]\n",
    "            #text = [token for token in text if not token in stop_words]\n",
    "            result.append(token)\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "#processed_docs = documents['Texto'].map(preprocess)\n",
    "processed_docs = documents['news'].map(preprocess)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0    [hace, años, caminaba, amiga, querida, miraflo...\n",
       "1    [esperado, maritza, garcía, dignidad, renuncia...\n",
       "2    [piensan, mujercitas, novela, escrita, louisa,...\n",
       "3    [fallecimiento, ágreda, calado, fondo, distint...\n",
       "4    [mario, maría, acha, presentan, amplia, instal...\n",
       "5    [katherine, subirana, abanto, feminismo, estim...\n",
       "6    [definir, pasa, mundo, sola, palabra, quizá, i...\n",
       "7    [niunamenos, consigna, marcado, últimos, días,...\n",
       "8    [américa, noticias, primera, edición, cumplió,...\n",
       "9    [premier, césar, villanueva, manifestado, días...\n",
       "Name: news, dtype: object"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[:10]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Bag of words on the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary = gensim.corpora.Dictionary(processed_docs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "34495"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(dictionary)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 abierta\n",
      "1 abusado\n",
      "2 abuso\n",
      "3 acababa\n",
      "4 acoso\n",
      "5 adecuarse\n",
      "6 adolescentes\n",
      "7 afectivas\n",
      "8 agresión\n",
      "9 agresores\n",
      "10 ahora\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "for k, v in dictionary.iteritems():\n",
    "    print(k, v)\n",
    "    count += 1\n",
    "    if count > 10:\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "dictionary.filter_extremes(no_below=15, no_above=0.5, keep_n=100000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(3, 1),\n",
       " (23, 1),\n",
       " (31, 1),\n",
       " (38, 1),\n",
       " (67, 1),\n",
       " (74, 2),\n",
       " (75, 1),\n",
       " (79, 1),\n",
       " (93, 2),\n",
       " (135, 1),\n",
       " (222, 1),\n",
       " (240, 1),\n",
       " (245, 2),\n",
       " (276, 1),\n",
       " (281, 1),\n",
       " (311, 1),\n",
       " (319, 1),\n",
       " (339, 1),\n",
       " (340, 1),\n",
       " (383, 1),\n",
       " (400, 1),\n",
       " (407, 2),\n",
       " (421, 1),\n",
       " (438, 1),\n",
       " (503, 1),\n",
       " (529, 1),\n",
       " (570, 1),\n",
       " (868, 1),\n",
       " (893, 1),\n",
       " (904, 1),\n",
       " (923, 1),\n",
       " (952, 1),\n",
       " (1117, 1),\n",
       " (1176, 1),\n",
       " (1183, 2),\n",
       " (1199, 1),\n",
       " (1204, 1),\n",
       " (1208, 1),\n",
       " (1223, 2),\n",
       " (1268, 1),\n",
       " (1291, 1),\n",
       " (1442, 1),\n",
       " (1489, 1),\n",
       " (1572, 1),\n",
       " (1623, 1),\n",
       " (1708, 1),\n",
       " (1759, 1),\n",
       " (1760, 1),\n",
       " (1825, 1),\n",
       " (2137, 1),\n",
       " (2145, 1),\n",
       " (2176, 1),\n",
       " (2199, 1),\n",
       " (2459, 5),\n",
       " (2704, 1),\n",
       " (2980, 1),\n",
       " (3116, 1),\n",
       " (3237, 1)]"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "bow_corpus = [dictionary.doc2bow(doc) for doc in processed_docs]\n",
    "bow_corpus[longitud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Word 3 (\"agresión\") appears 1 time.\n",
      "Word 23 (\"casa\") appears 1 time.\n",
      "Word 31 (\"cocina\") appears 1 time.\n",
      "Word 38 (\"contó\") appears 1 time.\n",
      "Word 67 (\"golpeado\") appears 1 time.\n",
      "Word 74 (\"hace\") appears 2 time.\n",
      "Word 75 (\"hacer\") appears 1 time.\n",
      "Word 79 (\"hombre\") appears 1 time.\n",
      "Word 93 (\"maría\") appears 2 time.\n",
      "Word 135 (\"puso\") appears 1 time.\n",
      "Word 222 (\"debido\") appears 1 time.\n",
      "Word 240 (\"familia\") appears 1 time.\n",
      "Word 245 (\"garcía\") appears 2 time.\n",
      "Word 276 (\"mujer\") appears 1 time.\n",
      "Word 281 (\"nunca\") appears 1 time.\n",
      "Word 311 (\"puede\") appears 1 time.\n",
      "Word 319 (\"relación\") appears 1 time.\n",
      "Word 339 (\"tres\") appears 1 time.\n",
      "Word 340 (\"triunfo\") appears 1 time.\n",
      "Word 383 (\"encuentra\") appears 1 time.\n",
      "Word 400 (\"hija\") appears 1 time.\n",
      "Word 407 (\"joven\") appears 2 time.\n",
      "Word 421 (\"madre\") appears 1 time.\n",
      "Word 438 (\"pareja\") appears 1 time.\n",
      "Word 503 (\"víctima\") appears 1 time.\n",
      "Word 529 (\"cortes\") appears 1 time.\n",
      "Word 570 (\"lima\") appears 1 time.\n",
      "Word 868 (\"sucedió\") appears 1 time.\n",
      "Word 893 (\"varias\") appears 1 time.\n",
      "Word 904 (\"último\") appears 1 time.\n",
      "Word 923 (\"agregó\") appears 1 time.\n",
      "Word 952 (\"pidió\") appears 1 time.\n",
      "Word 1117 (\"trabajar\") appears 1 time.\n",
      "Word 1176 (\"atacó\") appears 1 time.\n",
      "Word 1183 (\"cuchillo\") appears 2 time.\n",
      "Word 1199 (\"hermana\") appears 1 time.\n",
      "Word 1204 (\"hospital\") appears 1 time.\n",
      "Word 1208 (\"jueves\") appears 1 time.\n",
      "Word 1223 (\"policía\") appears 2 time.\n",
      "Word 1268 (\"estudiar\") appears 1 time.\n",
      "Word 1291 (\"sostuvo\") appears 1 time.\n",
      "Word 1442 (\"pedimos\") appears 1 time.\n",
      "Word 1489 (\"daño\") appears 1 time.\n",
      "Word 1572 (\"agredida\") appears 1 time.\n",
      "Word 1623 (\"sujeto\") appears 1 time.\n",
      "Word 1708 (\"ocasiones\") appears 1 time.\n",
      "Word 1759 (\"violento\") appears 1 time.\n",
      "Word 1760 (\"vivienda\") appears 1 time.\n",
      "Word 1825 (\"unidad\") appears 1 time.\n",
      "Word 2137 (\"cuidados\") appears 1 time.\n",
      "Word 2145 (\"intensivos\") appears 1 time.\n",
      "Word 2176 (\"villa\") appears 1 time.\n",
      "Word 2199 (\"piura\") appears 1 time.\n",
      "Word 2459 (\"palacios\") appears 5 time.\n",
      "Word 2704 (\"causó\") appears 1 time.\n",
      "Word 2980 (\"maltratos\") appears 1 time.\n",
      "Word 3116 (\"llegado\") appears 1 time.\n",
      "Word 3237 (\"profundos\") appears 1 time.\n"
     ]
    }
   ],
   "source": [
    "bow_doc_1920 = bow_corpus[longitud]\n",
    "\n",
    "for i in range(len(bow_doc_1920)):\n",
    "    print(\"Word {} (\\\"{}\\\") appears {} time.\".format(bow_doc_1920[i][0], \n",
    "                                                     dictionary[bow_doc_1920[i][0]], \n",
    "                                                     bow_doc_1920[i][1]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "from gensim import corpora, models\n",
    "\n",
    "tfidf = models.TfidfModel(bow_corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus_tfidf = tfidf[bow_corpus]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[(0, 0.05345995966850995),\n",
      " (1, 0.05364945640921876),\n",
      " (2, 0.059996180471412086),\n",
      " (3, 0.0774381197113865),\n",
      " (4, 0.05384100180303308),\n",
      " (5, 0.0710048073741156),\n",
      " (6, 0.10266253923999685),\n",
      " (7, 0.08087932610579768),\n",
      " (8, 0.05116490430037277),\n",
      " (9, 0.20993881359189076),\n",
      " (10, 0.15106719840380875),\n",
      " (11, 0.06651144588882818),\n",
      " (12, 0.08483293364484203),\n",
      " (13, 0.0611214967900566),\n",
      " (14, 0.04704647904849616),\n",
      " (15, 0.07200670154641677),\n",
      " (16, 0.07491778626496412),\n",
      " (17, 0.05722607576098639),\n",
      " (18, 0.06651144588882818),\n",
      " (19, 0.08550976920391888),\n",
      " (20, 0.05462858819120698),\n",
      " (21, 0.08375880015340331),\n",
      " (22, 0.06083339651770351),\n",
      " (23, 0.028850847010183263),\n",
      " (24, 0.06536796680451001),\n",
      " (25, 0.04785197122532196),\n",
      " (26, 0.04459876224681188),\n",
      " (27, 0.0769257185667533),\n",
      " (28, 0.08597641272916018),\n",
      " (29, 0.06612202853488033),\n",
      " (30, 0.035029901649261216),\n",
      " (31, 0.06904687463381896),\n",
      " (32, 0.1084608383139618),\n",
      " (33, 0.07369538599731291),\n",
      " (34, 0.056994467543176344),\n",
      " (35, 0.08597641272916018),\n",
      " (36, 0.07369538599731291),\n",
      " (37, 0.07255190691299475),\n",
      " (38, 0.044945049029139116),\n",
      " (39, 0.14401340309283353),\n",
      " (40, 0.07147777342155602),\n",
      " (41, 0.06574098640035722),\n",
      " (42, 0.13901420498566733),\n",
      " (43, 0.08597641272916018),\n",
      " (44, 0.06690961492305426),\n",
      " (45, 0.06690961492305426),\n",
      " (46, 0.0552431391506644),\n",
      " (47, 0.042990836132480725),\n",
      " (48, 0.06083339651770351),\n",
      " (49, 0.06536796680451001),\n",
      " (50, 0.07764899353635728),\n",
      " (51, 0.0685982993739504),\n",
      " (52, 0.04928159930983086),\n",
      " (53, 0.06651144588882818),\n",
      " (54, 0.0769257185667533),\n",
      " (55, 0.06361229635184569),\n",
      " (56, 0.0769257185667533),\n",
      " (57, 0.08375880015340331),\n",
      " (58, 0.0827460801597198),\n",
      " (59, 0.05769857779878298),\n",
      " (60, 0.038966864963161346),\n",
      " (61, 0.07919064165490153),\n",
      " (62, 0.045902999964178),\n",
      " (63, 0.07096417872591976),\n",
      " (64, 0.04652913495566824),\n",
      " (65, 0.06904687463381896),\n",
      " (66, 0.05364945640921876),\n",
      " (67, 0.07840305526672761),\n",
      " (68, 0.0589380884263956),\n",
      " (69, 0.03677863510784175),\n",
      " (70, 0.06394978801045643),\n",
      " (71, 0.06950710249283366),\n",
      " (72, 0.0652116715746354),\n",
      " (73, 0.1791770244437085),\n",
      " (74, 0.0823522593525884),\n",
      " (75, 0.11715072866445347),\n",
      " (76, 0.030629051064068463),\n",
      " (77, 0.04127342796792098),\n",
      " (78, 0.04306664237607084),\n",
      " (79, 0.026895023380958012),\n",
      " (80, 0.08597641272916018),\n",
      " (81, 0.04194939242513363),\n",
      " (82, 0.08375880015340331),\n",
      " (83, 0.06054990604799464),\n",
      " (84, 0.04913333253361839),\n",
      " (85, 0.039645140183515594),\n",
      " (86, 0.02927894833933853),\n",
      " (87, 0.040898434576453944),\n",
      " (88, 0.08178812922468093),\n",
      " (89, 0.05945923706644944),\n",
      " (90, 0.046150805071646095),\n",
      " (91, 0.04506199847264985),\n",
      " (92, 0.04026070797423749),\n",
      " (93, 0.03655944332636206),\n",
      " (94, 0.04565861296733361),\n",
      " (95, 0.030890765960937566),\n",
      " (96, 0.06904687463381896),\n",
      " (97, 0.05793963969918088),\n",
      " (98, 0.04565861296733361),\n",
      " (99, 0.12996013166072962),\n",
      " (100, 0.08087932610579768),\n",
      " (101, 0.06997960453063025),\n",
      " (102, 0.04403624591025586),\n",
      " (103, 0.05345995966850995),\n",
      " (104, 0.04017144946625155),\n",
      " (105, 0.09710473957171248),\n",
      " (106, 0.07147777342155602),\n",
      " (107, 0.052187367366263865),\n",
      " (108, 0.056097173210903045),\n",
      " (109, 0.07764899353635728),\n",
      " (110, 0.052187367366263865),\n",
      " (111, 0.023566763649835936),\n",
      " (112, 0.02490664131607327),\n",
      " (113, 0.12054176036229497),\n",
      " (114, 0.07556214005123507),\n",
      " (115, 0.056097173210903045),\n",
      " (116, 0.08597641272916018),\n",
      " (117, 0.07491778626496412),\n",
      " (118, 0.04805214740669171),\n",
      " (119, 0.08087932610579768),\n",
      " (120, 0.05403464063057854),\n",
      " (121, 0.07147777342155602),\n",
      " (122, 0.05442838519821574),\n",
      " (123, 0.13632160237250898),\n",
      " (124, 0.04798985344930022),\n",
      " (125, 0.05462858819120698),\n",
      " (126, 0.07491778626496412),\n",
      " (127, 0.05545281942463211),\n",
      " (128, 0.04506199847264985),\n",
      " (129, 0.08087932610579768),\n",
      " (130, 0.0617121440291028),\n",
      " (131, 0.050355732801269586),\n",
      " (132, 0.05843183180349336),\n",
      " (133, 0.07255190691299475),\n",
      " (134, 0.10966215853586275),\n",
      " (135, 0.06536796680451001),\n",
      " (136, 0.051429516308484004),\n",
      " (137, 0.07556214005123507),\n",
      " (138, 0.06054990604799464),\n",
      " (139, 0.058184026696025265),\n",
      " (140, 0.08597641272916018),\n",
      " (141, 0.08178812922468093),\n",
      " (142, 0.1301519525022955),\n",
      " (143, 0.054831079267931376),\n",
      " (144, 0.06773384615647939),\n",
      " (145, 0.07764899353635728),\n",
      " (146, 0.05083678795357601),\n",
      " (147, 0.051000086587540516),\n",
      " (148, 0.07764899353635728),\n",
      " (149, 0.0827460801597198),\n",
      " (150, 0.031371821113244),\n",
      " (151, 0.09828511627969537),\n",
      " (152, 0.05793963969918088),\n",
      " (153, 0.1654921603194396),\n",
      " (154, 0.20072884476916278),\n",
      " (155, 0.022949834837730436),\n",
      " (156, 0.07369538599731291),\n",
      " (157, 0.1234242880582056),\n",
      " (158, 0.06612202853488033),\n",
      " (159, 0.09280425052445045),\n",
      " (160, 0.11636805339205053),\n",
      " (161, 0.07894624317212715),\n",
      " (162, 0.032034245045255726),\n",
      " (163, 0.07764899353635728),\n",
      " (164, 0.03707517385183191),\n",
      " (165, 0.07147777342155602),\n",
      " (166, 0.0827460801597198),\n",
      " (167, 0.06731693806565398),\n",
      " (168, 0.05364945640921876),\n",
      " (169, 0.04117893293666267),\n",
      " (170, 0.08597641272916018),\n",
      " (171, 0.026520250331067804),\n",
      " (172, 0.06773384615647939),\n",
      " (173, 0.037378027057026274),\n",
      " (174, 0.08375880015340331),\n",
      " (175, 0.07623081474230371),\n",
      " (176, 0.050042135652501644)]\n"
     ]
    }
   ],
   "source": [
    "from pprint import pprint\n",
    "\n",
    "for doc in corpus_tfidf:\n",
    "    pprint(doc)\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using Bag of Words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model = gensim.models.LdaMulticore(bow_corpus, num_topics=3, id2word=dictionary, passes=5, workers=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.020*\"mujeres\" + 0.016*\"violencia\" + 0.015*\"mujer\" + 0.007*\"hombre\" + 0.006*\"perú\" + 0.006*\"país\" + 0.005*\"casos\" + 0.005*\"género\" + 0.005*\"solo\" + 0.004*\"víctimas\"\n",
      "Topic: 1 \n",
      "Words: 0.008*\"policía\" + 0.008*\"pareja\" + 0.008*\"según\" + 0.007*\"mujer\" + 0.007*\"víctima\" + 0.006*\"luego\" + 0.005*\"joven\" + 0.005*\"tras\" + 0.005*\"caso\" + 0.005*\"fiscalía\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"violencia\" + 0.007*\"casos\" + 0.006*\"nacional\" + 0.006*\"mujer\" + 0.006*\"perú\" + 0.005*\"persona\" + 0.005*\"país\" + 0.005*\"mujeres\" + 0.005*\"según\" + 0.005*\"dijo\"\n"
     ]
    }
   ],
   "source": [
    "\n",
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 \n",
      "Words: 0.020*\"mujeres\" + 0.016*\"violencia\" + 0.015*\"mujer\" + 0.007*\"hombre\" + 0.006*\"perú\" + 0.006*\"país\" + 0.005*\"casos\" + 0.005*\"género\" + 0.005*\"solo\" + 0.004*\"víctimas\"\n",
      "Topic: 1 \n",
      "Words: 0.008*\"policía\" + 0.008*\"pareja\" + 0.008*\"según\" + 0.007*\"mujer\" + 0.007*\"víctima\" + 0.006*\"luego\" + 0.005*\"joven\" + 0.005*\"tras\" + 0.005*\"caso\" + 0.005*\"fiscalía\"\n",
      "Topic: 2 \n",
      "Words: 0.009*\"violencia\" + 0.007*\"casos\" + 0.006*\"nacional\" + 0.006*\"mujer\" + 0.006*\"perú\" + 0.005*\"persona\" + 0.005*\"país\" + 0.005*\"mujeres\" + 0.005*\"según\" + 0.005*\"dijo\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model.print_topics(-1):\n",
    "    print('Topic: {} \\nWords: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cool! Can you distinguish different topics using the words in each topic and their corresponding weights?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Running LDA using TF-IDF"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "lda_model_tfidf = gensim.models.LdaMulticore(corpus_tfidf, num_topics=7, id2word=dictionary, passes=5, workers=4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Topic: 0 Word: 0.003*\"ruiz\" + 0.002*\"marysella\" + 0.002*\"violencia\" + 0.002*\"casos\" + 0.002*\"águila\" + 0.002*\"lima\" + 0.002*\"pizarro\" + 0.002*\"marcha\" + 0.002*\"mujer\" + 0.002*\"rumiche\"\n",
      "Topic: 1 Word: 0.004*\"papa\" + 0.004*\"perú\" + 0.003*\"kilómetros\" + 0.003*\"lluvias\" + 0.003*\"iglesia\" + 0.003*\"armas\" + 0.002*\"regiones\" + 0.002*\"francisco\" + 0.002*\"intensidad\" + 0.002*\"candidatos\"\n",
      "Topic: 2 Word: 0.003*\"policía\" + 0.003*\"hospital\" + 0.002*\"distrito\" + 0.002*\"arequipa\" + 0.002*\"maleta\" + 0.002*\"sujeto\" + 0.002*\"nacional\" + 0.002*\"salud\" + 0.002*\"pareja\" + 0.002*\"región\"\n",
      "Topic: 3 Word: 0.005*\"mujeres\" + 0.003*\"violencia\" + 0.003*\"mujer\" + 0.002*\"pareja\" + 0.002*\"joven\" + 0.002*\"hombre\" + 0.002*\"víctima\" + 0.002*\"policía\" + 0.002*\"sujeto\" + 0.002*\"cuerpo\"\n",
      "Topic: 4 Word: 0.002*\"accidente\" + 0.002*\"niños\" + 0.002*\"obra\" + 0.002*\"empresa\" + 0.002*\"vehículos\" + 0.002*\"persona\" + 0.002*\"tránsito\" + 0.002*\"rusia\" + 0.002*\"camión\" + 0.002*\"accidentes\"\n",
      "Topic: 5 Word: 0.003*\"villanueva\" + 0.002*\"pareja\" + 0.002*\"ministerio\" + 0.002*\"mimp\" + 0.002*\"agustino\" + 0.002*\"camarena\" + 0.002*\"víctima\" + 0.002*\"casos\" + 0.002*\"mujer\" + 0.002*\"policía\"\n",
      "Topic: 6 Word: 0.004*\"penal\" + 0.004*\"olórtiga\" + 0.003*\"prisión\" + 0.003*\"delito\" + 0.003*\"fiscal\" + 0.003*\"guerrero\" + 0.003*\"violencia\" + 0.003*\"sexual\" + 0.003*\"piura\" + 0.002*\"pena\"\n"
     ]
    }
   ],
   "source": [
    "for idx, topic in lda_model_tfidf.print_topics(-1):\n",
    "    print('Topic: {} Word: {}'.format(idx, topic))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Classification of the topics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA Bag of Words model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['joven',\n",
       " 'años',\n",
       " 'érika',\n",
       " 'palacios',\n",
       " 'garcía',\n",
       " 'encuentra',\n",
       " 'unidad',\n",
       " 'cuidados',\n",
       " 'intensivos',\n",
       " 'hospital',\n",
       " 'maría',\n",
       " 'auxiliadora',\n",
       " 'debido',\n",
       " 'profundos',\n",
       " 'cortes',\n",
       " 'causó',\n",
       " 'cuchillo',\n",
       " 'cocina',\n",
       " 'pareja',\n",
       " 'abimael',\n",
       " 'palacios',\n",
       " 'palacios',\n",
       " 'agresión',\n",
       " 'sucedió',\n",
       " 'casa',\n",
       " 'víctima',\n",
       " 'villa',\n",
       " 'maría',\n",
       " 'triunfo',\n",
       " 'familia',\n",
       " 'mujer',\n",
       " 'pidió',\n",
       " 'policía',\n",
       " 'capture',\n",
       " 'palacios',\n",
       " 'golpeado',\n",
       " 'varias',\n",
       " 'ocasiones',\n",
       " 'joven',\n",
       " 'llegado',\n",
       " 'piura',\n",
       " 'hace',\n",
       " 'estudiar',\n",
       " 'trabajar',\n",
       " 'lima',\n",
       " 'zulema',\n",
       " 'garcía',\n",
       " 'madre',\n",
       " 'agredida',\n",
       " 'contó',\n",
       " 'hace',\n",
       " 'tres',\n",
       " 'hija',\n",
       " 'puso',\n",
       " 'relación',\n",
       " 'palacios',\n",
       " 'agredía',\n",
       " 'enfureció',\n",
       " 'sujeto',\n",
       " 'último',\n",
       " 'jueves',\n",
       " 'atacó',\n",
       " 'cuchillo',\n",
       " 'vivienda',\n",
       " 'contaba',\n",
       " 'maltratos',\n",
       " 'causaba',\n",
       " 'hombre',\n",
       " 'pedimos',\n",
       " 'detengan',\n",
       " 'violento',\n",
       " 'puede',\n",
       " 'hacer',\n",
       " 'daño',\n",
       " 'sostuvo',\n",
       " 'hermana',\n",
       " 'agregó',\n",
       " 'érika',\n",
       " 'nunca',\n",
       " 'atrevió',\n",
       " 'denunciarlo',\n",
       " 'policía']"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "processed_docs[longitud]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9893956780433655\t \n",
      "Topic: 0.009*\"mujer\" + 0.008*\"pareja\" + 0.007*\"policía\" + 0.007*\"según\" + 0.007*\"víctima\" + 0.006*\"luego\" + 0.005*\"joven\" + 0.005*\"caso\" + 0.005*\"dijo\" + 0.005*\"tras\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model[bow_corpus[longitud]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Performance evaluation by classifying sample document using LDA TF-IDF model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Score: 0.9875385165214539\t \n",
      "Topic: 0.004*\"policía\" + 0.003*\"pareja\" + 0.003*\"sujeto\" + 0.003*\"menor\" + 0.003*\"crimen\" + 0.003*\"víctima\" + 0.003*\"niña\" + 0.003*\"fiscalía\" + 0.003*\"prisión\" + 0.002*\"uribe\"\n"
     ]
    }
   ],
   "source": [
    "for index, score in sorted(lda_model_tfidf[bow_corpus[longitud]], key=lambda tup: -1*tup[1]):\n",
    "    print(\"\\nScore: {}\\t \\nTopic: {}\".format(score, lda_model_tfidf.print_topic(index, 10)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our test document has the highest probability to be part of the topic on the top."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Testing model on unseen document"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Score: 0.8667702078819275\t Topic: 0.009*\"mujer\" + 0.008*\"pareja\" + 0.007*\"policía\" + 0.007*\"según\" + 0.007*\"víctima\" + 0.006*\"luego\" + 0.005*\"joven\" + 0.005*\"caso\" + 0.005*\"dijo\" + 0.005*\"tras\"\n",
      "Score: 0.06903830170631409\t Topic: 0.018*\"mujeres\" + 0.016*\"violencia\" + 0.013*\"mujer\" + 0.007*\"casos\" + 0.006*\"país\" + 0.006*\"perú\" + 0.005*\"hombre\" + 0.005*\"solo\" + 0.005*\"género\" + 0.004*\"persona\"\n",
      "Score: 0.06419151276350021\t Topic: 0.006*\"nacional\" + 0.005*\"perú\" + 0.005*\"según\" + 0.005*\"dijo\" + 0.005*\"penal\" + 0.004*\"fiscal\" + 0.004*\"caso\" + 0.004*\"piura\" + 0.004*\"persona\" + 0.004*\"lima\"\n"
     ]
    }
   ],
   "source": [
    "unseen_document = 'el ministerio de justicia apoyo mujer en la calle'\n",
    "bow_vector = dictionary.doc2bow(preprocess(unseen_document))\n",
    "\n",
    "for index, score in sorted(lda_model[bow_vector], key=lambda tup: -1*tup[1]):\n",
    "    print(\"Score: {}\\t Topic: {}\".format(score, lda_model.print_topic(index, 10)))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
